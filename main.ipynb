{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03ed849c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\PUNAM\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import re          \n",
    "import os          \n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb4d46dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 150/150 [03:40<00:00,  1.47s/it]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel('20211030 Test Assignment/input.xlsx')\n",
    "\n",
    "for i in tqdm(range(0, len(data))):\n",
    "    headers = {'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:32.0) Gecko/20100101 Firefox/32.0'}\n",
    "    url = data['URL'][i]\n",
    "    r = requests.get(url, headers=headers)\n",
    "    htmlcontent = r.content\n",
    "    soup = BeautifulSoup(htmlcontent, 'html.parser')\n",
    "    mydivs = soup.find(\"div\", {\"class\": \"td-post-content\"})\n",
    "    #Removing pre tag from mydivs\n",
    "    try:\n",
    "        mydivs.pre.decompose()\n",
    "    except:\n",
    "        pass\n",
    "    #Storing news articles in articles directory\n",
    "    text_file = open('articles/' + str(i + 1) + '.txt', \"w\", encoding=\"utf-8\")\n",
    "    text_file.write(soup.title.getText())\n",
    "    text_file.write(mydivs.getText() if mydivs else \"pass\")\n",
    "    text_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d52704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Output Data Structure.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c12a7ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 150/150 [00:15<00:00,  9.38it/s]\n"
     ]
    }
   ],
   "source": [
    "#Reading all files available in the articles directory.\n",
    "#Article directory consists of all 150 articles stored in the text format \n",
    "for filename1 in tqdm(os.listdir('articles')):\n",
    "    f = open('articles/' + filename1, 'r', encoding=\"utf8\") \n",
    "    text = f.read()                                         \n",
    "    f.close()              \n",
    "    #Converting text into lowercases\n",
    "    text1 = text.lower()   \n",
    "    #Tocknizing text1 with the help of nltk word_toknize method\n",
    "    text2 = word_tokenize(text1)                            \n",
    "    sent = sent_tokenize(text1)                             \n",
    "    #Removing all the punctuation from the text\n",
    "    text3 = []                            \n",
    "    for i in text2:                       \n",
    "        res = re.sub(r'[^ \\w\\s]', \"\", i)  \n",
    "        if res != \"\":                     \n",
    "            text3.append(res)             \n",
    "    #Creating stopword list from the given stopwords from stopwords directory \n",
    "    stopwords = []                                                          \n",
    "    for filename in os.listdir('20211030 Test Assignment/StopWords'):       \n",
    "        f1 = open('20211030 Test Assignment/StopWords/' + filename, 'r')    \n",
    "        for i in f1:                                                        \n",
    "         # print(i)                                                      \n",
    "            if '|' in i:                                                    \n",
    "                x = re.split(\"\\s\", i)                                       \n",
    "                x.remove(\"\")                                                \n",
    "                stopwords.append(x[0])                                      \n",
    "            else:                                                           \n",
    "                stopwords.append(i.strip())                                 \n",
    "        f1.close()                                                          \n",
    "    #Excluding all the stopwords form the text\n",
    "    text4 = []                \n",
    "    for i in text3:           \n",
    "        if i not in stopwords:\n",
    "            text4.append(i)   \n",
    "\n",
    "    # Reading -ve and +ve words from txt file                                       \n",
    "    f2 = open('20211030 Test Assignment/MasterDictionary/negative-words.txt', 'r')  \n",
    "    nve =  f2.read().split()                                                                                                         \n",
    "    f2.close()                                                                      \n",
    "    f2 = open('20211030 Test Assignment/MasterDictionary/positive-words.txt', 'r')  \n",
    "    pve = f2.read().split()                                                        \n",
    "    f2.close()                                                                      \n",
    "\n",
    "    # Counting negative and positive words news article  \n",
    "    positiveScore, negativeScore = 0, 0                  \n",
    "    for i in text4:                                      \n",
    "        if i in pve:                                     \n",
    "            positiveScore += 1                           \n",
    "        elif i in nve:                                   \n",
    "            negativeScore += 1                           \n",
    "    #Calculating polarity Score\n",
    "    polarityScore = (positiveScore - negativeScore) / ((positiveScore + negativeScore) + 0.000001)\n",
    "    #Calculating subjectivity Score\n",
    "    subjectivityScore = (positiveScore + negativeScore) / (len(text4) + 0.000001)\n",
    "    #Calculating average Sentence Length\n",
    "    averageSentenceLength = len(text3) / len(sent)\n",
    "    #Counting complex words\n",
    "    complexwords = 0                                                      \n",
    "    for i in text4:                                                       \n",
    "        s = 0                                                             \n",
    "        for j in i:                                                       \n",
    "            if (j == 'a' or j == 'e' or j == 'i' or j == 'o' or j == 'u'):\n",
    "                s += 1                                                    \n",
    "        if s > 2:                                                         \n",
    "            complexwords = complexwords + 1                     \n",
    "    #Calculating percentage of Complex words\n",
    "    percentageofComplexwords = complexwords / len(text4)\n",
    "    #Calculating fog Index\n",
    "    fogIndex = 0.4 * (averageSentenceLength + percentageofComplexwords)\n",
    "    #Calculating average Number of Words PerSentence\n",
    "    averageNumberofWordsPerSentence = len(text4) / len(sent)\n",
    "    \n",
    "    fname = int(filename1.removesuffix('.txt')) - 1\n",
    "    #Counting personal pronouns used in article\n",
    "    personal_noun =['I', 'we','my','ours', 'us','My','We','Ours','Us',] \n",
    "    personalPronouns=0\n",
    "    for word in text3:\n",
    "        if word in personal_noun:\n",
    "            personalPronouns+=1\n",
    "    \n",
    "    #Calculating average Word Length\n",
    "    letterCount = 0                             \n",
    "    for i in text4:                             \n",
    "        for j in i:                             \n",
    "            letterCount += 1                    \n",
    "    averageWordLength = letterCount / len(text4)\n",
    "   \n",
    "    #Counting total syllabul present in article\n",
    "    syllable = 0\n",
    "    for i in text4:\n",
    "        s = 0\n",
    "        for j in i:\n",
    "            if (j == 'a' or j == 'e' or j == 'i' or j == 'o' or j == 'u'):\n",
    "                s += 1\n",
    "        if i.endswith(\"es\") or i.endswith(\"ed\"):\n",
    "            s -= 1\n",
    "        if s > 0:\n",
    "            syllable +=1\n",
    "    \n",
    "    #Storing all the computed data in their respective column\n",
    "    df.at[fname,'POSITIVE SCORE'] = positiveScore\n",
    "    df.at[fname,'NEGATIVE SCORE'] = negativeScore\n",
    "    df.at[fname,'POLARITY SCORE'] = polarityScore\n",
    "    df.at[fname,'SUBJECTIVITY SCORE'] = subjectivityScore\n",
    "    df.at[fname,'AVG SENTENCE LENGTH'] = averageSentenceLength\n",
    "    df.at[fname,'PERCENTAGE OF COMPLEX WORDS'] = percentageofComplexwords\n",
    "    df.at[fname,'FOG INDEX'] = fogIndex\n",
    "    df.at[fname,'AVG NUMBER OF WORDS PER SENTENCE'] = averageNumberofWordsPerSentence \n",
    "    df.at[fname,'COMPLEX WORD COUNT'] = complexwords\n",
    "    df.at[fname,'WORD COUNT'] = len(text4)\n",
    "    df.at[fname,'SYLLABLE PER WORD'] = syllable/len(text4)\n",
    "    df.at[fname,'PERSONAL PRONOUNS'] = personalPronouns\n",
    "    df.at[fname,'AVG WORD LENGTH'] = averageWordLength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3e27449",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({'URL_ID':int})\n",
    "df.to_csv('Output Data Structure.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bdba32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
